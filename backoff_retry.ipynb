{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f54d42b3-e4f7-41a4-9566-edfc932b653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_random_exponential, wait_exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7831b13-0b08-449d-b9f4-8814ca45b387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait strategy that applies exponential backoff.\n",
      "\n",
      "    It allows for a customized multiplier and an ability to restrict the\n",
      "    upper and lower limits to some maximum and minimum value.\n",
      "\n",
      "    The intervals are fixed (i.e. there is no jitter), so this strategy is\n",
      "    suitable for balancing retries against latency when a required resource is\n",
      "    unavailable for an unknown duration, but *not* suitable for resolving\n",
      "    contention between multiple processes for a shared resource. Use\n",
      "    wait_random_exponential for the latter case.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(wait_exponential.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52265a47-31d1-4991-b8e5-7251d02d12d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random wait with exponentially widening window.\n",
      "\n",
      "    An exponential backoff strategy used to mediate contention between multiple\n",
      "    uncoordinated processes for a shared resource in distributed systems. This\n",
      "    is the sense in which \"exponential backoff\" is meant in e.g. Ethernet\n",
      "    networking, and corresponds to the \"Full Jitter\" algorithm described in\n",
      "    this blog post:\n",
      "\n",
      "    https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/\n",
      "\n",
      "    Each retry occurs at a random time in a geometrically expanding interval.\n",
      "    It allows for a custom multiplier and an ability to restrict the upper\n",
      "    limit of the random interval to some maximum value.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        wait_random_exponential(multiplier=0.5,  # initial window 0.5s\n",
      "                                max=60)          # max 60s timeout\n",
      "\n",
      "    When waiting for an unavailable resource to become available again, as\n",
      "    opposed to trying to resolve contention for a shared resource, the\n",
      "    wait_exponential strategy (which uses a fixed interval) may be preferable.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(wait_random_exponential.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dfa4c7-bf6f-4f76-ad94-25ba0998aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e82e3d-024f-4e9b-9717-ea56feae1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb772cf0-9b90-4dd2-b72e-c5eef14cbe9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-8S4YaZlHPixVaxLZlcw7ByHm9HeQu', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text=' I was whining to veteran customer service representatives about my work environment.They laughed and')], created=1701701392, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=5, total_tokens=21))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return client.completions.create(**kwargs)\n",
    " \n",
    "completion_with_backoff(model=\"gpt-3.5-turbo-instruct\", prompt=\"Once upon a time,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d59e14-404c-4335-a115-50261f1c496e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
